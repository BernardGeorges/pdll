{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cdb1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f11c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['data_id', 'target_unique_vals', 'NumberOfFeatures_post_processing',\n",
       "       'pairwise_complexity_post_processing', 'base_fit_time',\n",
       "       'base_score_time', 'base_test_f1_macro', 'base_train_f1_macro',\n",
       "       'base_test_neg_log_loss', 'base_train_neg_log_loss',\n",
       "       'base_test_neg_brier_score', 'base_train_neg_brier_score',\n",
       "       'base_n_jobs_cv', 'base_cpu', 'base_ram', 'base_test_f1', 'base_time',\n",
       "       'pdc_fit_time', 'pdc_score_time', 'pdc_test_f1_macro',\n",
       "       'pdc_train_f1_macro', 'pdc_test_neg_log_loss', 'pdc_train_neg_log_loss',\n",
       "       'pdc_test_neg_brier_score', 'pdc_train_neg_brier_score',\n",
       "       'pdc_n_jobs_cv', 'pdc_cpu', 'pdc_ram', 'pdc_test_f1', 'pdc_time',\n",
       "       'pdc_ram_max', 'data_time', 'name', 'version', 'uploader', 'status',\n",
       "       'format', 'MajorityClassSize', 'MaxNominalAttDistinctValues',\n",
       "       'MinorityClassSize', 'NumberOfClasses', 'NumberOfFeatures',\n",
       "       'NumberOfInstances', 'NumberOfInstancesWithMissingValues',\n",
       "       'NumberOfMissingValues', 'NumberOfNumericFeatures',\n",
       "       'NumberOfSymbolicFeatures', 'MinorityClassRatio', 'complexity',\n",
       "       'pairwise_complexity', 'NumberOfInstances2', 'base_train_f1',\n",
       "       'pdc_train_f1', 'diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load the parquet file\n",
    "df = pd.read_parquet('MLPClassifier_base.parquet')\n",
    "df_ad = pd.read_parquet('MLPClassifier_RQ2.parquet')\n",
    "# Step 2: Extract the 'pdc_test_f1' column\n",
    "data = df['pdc_test_f1'].dropna()  # Drop NaNs for a clean test\n",
    "data_ad = df_ad['pdc_test_f1'].dropna()\n",
    "# OPTIONAL: If you want to split the data into two independent groups\n",
    "# For example, split based on even vs odd index (you can choose a better logic based on your context)\n",
    "group1 = data\n",
    "group2 = data_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4013536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual t-test calculation:\n",
      "t-statistic = -0.5984\n",
      "p-value = 0.5499\n",
      "Result: Not statistically significant (p ≥ 0.05) — fail to reject the null hypothesis.\n",
      "\n",
      "Using scipy.stats.ttest_ind:\n",
      "t-statistic = -0.5984\n",
      "p-value = 0.5499\n",
      "Result: Not statistically significant (p ≥ 0.05) — fail to reject the null hypothesis.\n"
     ]
    }
   ],
   "source": [
    "# Manual calculation\n",
    "n1 = len(group1)\n",
    "n2 = len(group2)\n",
    "\n",
    "mean1 = np.mean(group1)\n",
    "mean2 = np.mean(group2)\n",
    "\n",
    "var1 = np.var(group1, ddof=1)\n",
    "var2 = np.var(group2, ddof=1)\n",
    "\n",
    "# Pooled standard deviation\n",
    "pooled_std = np.sqrt(((n1 - 1)*var1 + (n2 - 1)*var2) / (n1 + n2 - 2))\n",
    "standard_error = pooled_std * np.sqrt(1/n1 + 1/n2)\n",
    "\n",
    "# t-statistic\n",
    "t_statistic = (mean1 - mean2) / standard_error\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n1 + n2 - 2\n",
    "\n",
    "# Two-tailed p-value\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_statistic), df))\n",
    "\n",
    "# Significance level\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"Manual t-test calculation:\")\n",
    "print(f\"t-statistic = {t_statistic:.4f}\")\n",
    "print(f\"p-value = {p_value:.4f}\")\n",
    "if p_value < alpha:\n",
    "    print(f\"Result: Statistically significant (p < {alpha}) — reject the null hypothesis.\")\n",
    "else:\n",
    "    print(f\"Result: Not statistically significant (p ≥ {alpha}) — fail to reject the null hypothesis.\")\n",
    "\n",
    "# Using scipy\n",
    "t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=True)\n",
    "\n",
    "print(\"\\nUsing scipy.stats.ttest_ind:\")\n",
    "print(f\"t-statistic = {t_stat:.4f}\")\n",
    "print(f\"p-value = {p_val:.4f}\")\n",
    "if p_val < alpha:\n",
    "    print(f\"Result: Statistically significant (p < {alpha}) — reject the null hypothesis.\")\n",
    "else:\n",
    "    print(f\"Result: Not statistically significant (p ≥ {alpha}) — fail to reject the null hypothesis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff4d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc93dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdll",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
